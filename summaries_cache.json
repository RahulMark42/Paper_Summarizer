{"gsplat is an open-source library designed for training and developing Gaussian Splatting methods. It features a front-end with Python bindings compatible with the PyTorch library and a back-end with highly optimized CUDA kernels. gsplat offers numerous features that enhance the optimization of Gaussian Splatting models, which include optimization improvements for speed, memory, and convergence times. Experimental results demonstrate that gsplat achieves up to 10% less training time and 4x less memory than the original implementation. Utilized in several research projects, gsplat is actively maintained on GitHub. Source code is available at https://github.com/nerfstudio-project/gsplat under Apache License 2.0. We welcome contributions from the open-source community.": "This research paper introduces gsplat, an open-source Python library built on PyTorch and CUDA for training and developing Gaussian Splatting models.  Key features include optimized CUDA kernels resulting in significant performance improvements.  Experimental results show gsplat achieves up to a 10% reduction in training time and a 4x reduction in memory usage compared to the original implementation.  The library is actively maintained on GitHub and welcomes community contributions.\n", "We consider online statistical inference of constrained stochastic nonlinear optimization problems. We apply the Stochastic Sequential Quadratic Programming (StoSQP) method to solve these problems, which can be regarded as applying second-order Newton's method to the Karush-Kuhn-Tucker (KKT) conditions. In each iteration, the StoSQP method computes the Newton direction by solving a quadratic program, and then selects a proper adaptive stepsize $\\bar{\\alpha}_t$ to update the primal-dual iterate. To reduce dominant computational cost of the method, we inexactly solve the quadratic program in each iteration by employing an iterative sketching solver. Notably, the approximation error of the sketching solver need not vanish as iterations proceed, meaning that the per-iteration computational cost does not blow up. For the above StoSQP method, we show that under mild assumptions, the rescaled primal-dual sequence $1/\\sqrt{\\bar{\\alpha}_t}\\cdot (x_t -x^\\star, \\lambda_t - \\lambda^\\star)$ converges to a mean-zero Gaussian distribution with a nontrivial covariance matrix depending on the underlying sketching distribution. To perform inference in practice, we also analyze a plug-in covariance matrix estimator. We illustrate the asymptotic normality result of the method both on benchmark nonlinear problems in CUTEst test set and on linearly/nonlinearly constrained regression problems.": "This research paper introduces an online statistical inference method for constrained stochastic nonlinear optimization problems.  The core approach uses a Stochastic Sequential Quadratic Programming (StoSQP) method, essentially a second-order Newton method applied to the Karush-Kuhn-Tucker (KKT) conditions.  To improve computational efficiency, the quadratic program in each StoSQP iteration is solved inexactly using an iterative sketching solver.  Crucially, the approximation error from this solver doesn't need to decrease over iterations, maintaining low per-iteration cost.\n\nThe key theoretical contribution is proving that, under mild assumptions, the rescaled difference between the iterates and the optimal solution converges to a Gaussian distribution. This asymptotic normality allows for statistical inference.  The paper further provides a plug-in estimator for the covariance matrix of this Gaussian distribution, enabling practical inference.  Finally, the method's effectiveness is demonstrated through experiments on benchmark nonlinear problems and constrained regression problems.  In short, the paper presents a computationally efficient method for solving constrained stochastic nonlinear optimization problems and performing associated statistical inference.\n", "While many Machine Learning methods have been developed or transposed on Riemannian manifolds to tackle data with known non-Euclidean geometry, Optimal Transport (OT) methods on such spaces have not received much attention. The main OT tool on these spaces is the Wasserstein distance, which suffers from a heavy computational burden. On Euclidean spaces, a popular alternative is the Sliced-Wasserstein distance, which leverages a closed-form solution of the Wasserstein distance in one dimension, but which is not readily available on manifolds. In this work, we derive general constructions of Sliced-Wasserstein distances on Cartan-Hadamard manifolds, Riemannian manifolds with non-positive curvature, which include among others Hyperbolic spaces or the space of Symmetric Positive Definite matrices. Then, we propose different applications such as classification of documents with a suitably learned ground cost on a manifold, and data set comparison on a product manifold. Additionally, we derive non-parametric schemes to minimize these new distances by approximating their Wasserstein gradient flows.": "This research paper introduces new methods for calculating Sliced-Wasserstein distances on Riemannian manifolds, specifically Cartan-Hadamard manifolds (manifolds with non-positive curvature).  The key ideas are:\n\n1. **Addressing the computational cost of Wasserstein distance:**  Traditional Wasserstein distance calculations on manifolds are computationally expensive.  This paper proposes using the Sliced-Wasserstein distance, a computationally cheaper alternative commonly used in Euclidean spaces, as a solution.\n\n2. **Extending Sliced-Wasserstein to Riemannian manifolds:** The main contribution is the derivation of formulas for calculating Sliced-Wasserstein distances on Cartan-Hadamard manifolds, a class of manifolds that includes important examples like hyperbolic spaces and spaces of symmetric positive definite matrices.  This extends the applicability of this efficient distance metric beyond Euclidean settings.\n\n3. **Practical applications:** The paper demonstrates the utility of the proposed methods through applications in document classification (using a learned cost function on a manifold) and dataset comparison (on a product manifold).\n\n4. **Gradient flow optimization:**  Non-parametric schemes for minimizing the new Sliced-Wasserstein distances are developed using approximations of their Wasserstein gradient flows. This provides a practical way to utilize the derived distances in various machine learning tasks.\n\nIn essence, the paper bridges a gap in the field of Optimal Transport by providing efficient and applicable methods for computing distances on non-Euclidean data residing on Riemannian manifolds.\n", "The acceleration of gradient-based optimization methods is a subject of significant practical and theoretical importance, particularly within machine learning applications. While much attention has been directed towards optimizing within Euclidean space, the need to optimize over spaces of probability measures in machine learning motivates the exploration of accelerated gradient methods in this context, too. To this end, we introduce a Hamiltonian-flow approach analogous to momentum-based approaches in Euclidean space. We demonstrate that, in the continuous-time setting, algorithms based on this approach can achieve convergence rates of arbitrarily high order. We complement our findings with numerical examples.": "This research paper explores accelerated gradient methods for optimizing over probability measures, a crucial need in machine learning.  Instead of the typical Euclidean space optimization, the authors propose a novel Hamiltonian-flow approach, analogous to momentum methods used in Euclidean space.  Their key finding is that, theoretically in continuous time, this Hamiltonian-flow approach allows for achieving arbitrarily high-order convergence rates.  Numerical examples support their findings.  In essence, the paper presents a new, potentially highly efficient method for optimizing in the complex space of probability measures, a significant advancement for machine learning algorithms.\n", "Gaussian processes are pervasive in functional data analysis, machine learning, and spatial statistics for modeling complex dependencies. Scientific data are often heterogeneous in their inputs and contain multiple known discrete groups of samples; thus, it is desirable to leverage the similarity among groups while accounting for heterogeneity across groups. We propose multi-group Gaussian processes (MGGPs) defined over $\\mathbb{R}^p\\times \\mathscr{C}$, where $\\mathscr{C}$ is a finite set representing the group label, by developing general classes of valid (positive definite) covariance functions on such domains. MGGPs are able to accurately recover relationships between the groups and efficiently share strength across samples from all groups during inference, while capturing distinct group-specific behaviors in the conditional posterior distributions. We demonstrate inference in MGGPs through simulation experiments, and we apply our proposed MGGP regression framework to gene expression data to illustrate the behavior and enhanced inferential capabilities of multi-group Gaussian processes by jointly modeling continuous and categorical variables.": "This research paper introduces Multi-Group Gaussian Processes (MGGPs) as a novel method for modeling data with both continuous and categorical variables.  The key idea is to extend Gaussian Processes (GPs) to handle data divided into known discrete groups.  MGGPs achieve this by defining covariance functions over a combined domain of continuous input features (in $\\mathbb{R}^p$) and a discrete group label ($\\mathscr{C}$). This allows MGGPs to:\n\n* **Leverage group similarity:** The model efficiently shares information across groups, improving inference accuracy, particularly when data within individual groups is scarce.\n* **Capture group-specific behavior:**  Despite sharing information, MGGPs allow for distinct behaviors within each group, reflected in the conditional posterior distributions.\n* **Handle heterogeneous data:**  The framework specifically addresses the challenge of analyzing scientific data with mixed continuous and categorical input variables.\n\nThe authors demonstrate the effectiveness of MGGPs through simulations and a real-world application to gene expression data, highlighting the improved inferential capabilities compared to standard GP approaches.  The core contribution is the development of valid covariance functions for this mixed data type, enabling the efficient and accurate modeling of multi-group data.\n", "Robustness to malicious attacks is of paramount importance for distributed learning. Existing works usually consider the classical Byzantine attacks model, which assumes that some workers can send arbitrarily malicious messages to the server and disturb the aggregation steps of the distributed learning process. To defend against such worst-case Byzantine attacks, various robust aggregators have been proposed. They are proven to be effective and much superior to the often-used mean aggregator. In this paper, however, we demonstrate that the robust aggregators are too conservative for a class of weak but practical malicious attacks, known as label poisoning attacks, where the sample labels of some workers are poisoned. Surprisingly, we are able to show that the mean aggregator is more robust than the state-of-the-art robust aggregators in theory, given that the distributed data are sufficiently heterogeneous. In fact, the learning error of the mean aggregator is proven to be order-optimal in this case. Experimental results corroborate our theoretical findings, showing the superiority of the mean aggregator under label poisoning attacks.": "This research paper challenges the common assumption that robust aggregators (designed to withstand worst-case Byzantine attacks in distributed learning) are always superior to the simple mean aggregator.  The authors demonstrate that under a more realistic attack\u2014label poisoning\u2014where only data labels are manipulated, the mean aggregator can be surprisingly more robust, especially when the data across different workers is sufficiently heterogeneous.  The key finding is that the mean aggregator's error rate is theoretically optimal in this scenario, outperforming state-of-the-art robust aggregators.  Experimental results validate the theoretical analysis, showing the mean aggregator's superior performance against label poisoning attacks.  In essence, the paper argues that the robustness of aggregation methods depends heavily on the nature of the attack, and that overly robust methods designed for worst-case scenarios might be less effective against more subtle, yet practical, attacks.\n", "In this paper, we consider federated Q-learning, which aims to learn an optimal Q-function by periodically aggregating local Q-estimates trained on local data alone. Focusing on infinite-horizon tabular Markov decision processes, we provide sample complexity guarantees for both the synchronous and asynchronous variants of federated Q-learning, which exhibit a linear speedup with respect to the number of agents and near-optimal dependencies on other salient problem parameters. In the asynchronous setting, existing analyses of federated Q-learning, which adopt an equally weighted averaging of local Q-estimates, require that every agent covers the entire state-action space. In contrast, our improved sample complexity scales inverse proportionally to the minimum entry of the average stationary state-action occupancy distribution of all agents, thus only requiring the agents to collectively cover the entire state-action space, unveiling the blessing of heterogeneity. However, its sample complexity still suffers when the local trajectories are highly heterogeneous. In response, we propose a novel federated Q-learning algorithm with importance averaging, giving larger weights to more frequently visited state-action pairs, which achieves a robust linear speedup as if all trajectories are centrally processed, regardless of the heterogeneity of local behavior policies.": "This research paper analyzes federated Q-learning, a method for training reinforcement learning agents distributed across multiple devices.  The key contributions are:\n\n* **Sample Complexity Bounds:** The authors derive sample complexity guarantees for both synchronous and asynchronous federated Q-learning in tabular Markov Decision Processes (MDPs).  These bounds show a linear speedup in performance compared to a single agent, meaning more agents significantly reduce the time to learn.\n\n* **Handling Asynchronous and Heterogeneous Agents:**  The paper improves upon existing analyses of asynchronous federated Q-learning.  Unlike previous work requiring each agent to explore the entire state-action space, the improved analysis only needs the *collective* of agents to cover it, allowing for heterogeneous agent behavior. This shows a \"blessing of heterogeneity.\"\n\n* **Importance Averaging for Robustness:**  Addressing the issue of poor performance with highly heterogeneous local trajectories, the authors propose a novel algorithm using *importance averaging*.  This method weights local Q-estimates based on how frequently state-action pairs are visited, achieving a robust linear speedup even with diverse agent behaviors, essentially mimicking the performance of centralized training.\n\nIn short, the paper provides theoretical guarantees for the efficiency of federated Q-learning, showcasing its scalability and robustness through improved algorithms and analysis, particularly in the presence of heterogeneous agents and data.\n", "PyTorch 2.x introduces a compiler designed to accelerate deep learning programs. However, for machine learning researchers, fully leveraging the PyTorch compiler can be challenging due to its operation at the Python bytecode level, making it appear as an opaque box. To address this, we introduce depyf, a tool designed to demystify the inner workings of the PyTorch compiler. depyf decompiles the bytecode generated by PyTorch back into equivalent source code and establishes connections between the code objects in the memory and their counterparts in source code format on the disk. This feature enables users to step through the source code line by line using debuggers, thus enhancing their understanding of the underlying processes. Notably, depyf is non-intrusive and user-friendly, primarily relying on two convenient context managers for its core functionality. The project is openly available at https://github.com/thuml/depyf and is recognized as a PyTorch ecosystem project at https://pytorch.org/blog/introducing-depyf.": "This research paper introduces `depyf`, a tool designed to improve the understandability and debuggability of the PyTorch 2.x compiler.  The PyTorch compiler operates at the bytecode level, making it difficult for researchers to trace its actions.  `depyf` addresses this by decompiling the generated bytecode back into readable source code, linking in-memory code objects to their on-disk source code counterparts. This allows users to use debuggers to step through the compilation process line by line, providing crucial insights into how the compiler transforms their code.  `depyf` is presented as a user-friendly, non-intrusive tool implemented using context managers.  The project is publicly available on GitHub.\n"}